{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import collections\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSM_FILE = \"Seattlemap\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "# Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'w') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Patters to search for tag attribute 'K' with lower alphabets, colons and problem characters\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Counting the lower, lower_colon and problem chars\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        # YOUR CODE HERE\n",
    "        l = lower.search(element.attrib['k'])\n",
    "        lc = lower_colon.search(element.attrib['k'])\n",
    "        pc = problemchars.search(element.attrib['k'])\n",
    "        if l:\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lc:\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif pc:\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "        \n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining keys dictionary\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 234007, 'lower_colon': 111321, 'other': 7884, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "#testing the count of lower , lower_colon and problem chars\n",
    "def test():\n",
    "    # You can use another testfile 'map.osm' to look at your solution\n",
    "    # Note that the assertion below will be incorrect then.\n",
    "    # Note as well that the test function here is only used in the Test Run;\n",
    "    # when you submit, your code will be checked against a different dataset.\n",
    "    keys = process_map(OSM_FILE)\n",
    "    pprint.pprint(keys)\n",
    "    #assert keys == {'lower': 5, 'lower_colon': 0, 'other': 1, 'problemchars': 1}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from audit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "\n",
    "    users = process_map(SAMPLE_FILE)\n",
    "    pprint.pprint(len(users))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Street Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = collections.defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "\n",
    "    \n",
    "    for key,value in mapping.iteritems():\n",
    "        key_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "        m = key_type_re.search(name)\n",
    "        if m:\n",
    "            key_type = m.group()\n",
    "        if key_type in mapping.keys():\n",
    "            # substitute the street_type for its clean version in 'name'\n",
    "            name = re.sub( key_type, mapping[key_type], name)\n",
    "            \n",
    "\n",
    "        return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "defaultdict(<type 'set'>, {'Northeast': set(['M Street Northeast']), 'North': set(['Washington Avenue North', 'Park Avenue North']), 'West': set(['Andover Park West']), 'St': set(['NE 17th St', 'S 2nd St']), 'Southeast': set(['126th Avenue Southeast', '224th Avenue Southeast', '227th Avenue Southeast', 'Auburn Enumclaw Road Southeast', '185th Avenue Southeast', '130th Avenue Southeast', '125th Place Southeast', '31st Avenue Southeast', '225th Avenue Southeast', '64th Court Southeast', '254th Way Southeast', '108th Avenue Southeast', '124th Place Southeast']), 'S': set(['Logan Ave S', 'River Avenue S']), 'Highway': set(['East Valley Highway']), 'Way': set(['Southwest Grady Way', 'Milton Way', 'S Grady Way', 'Outlet Collection Way', 'Southeast 318th Way']), 'Ave': set(['East Main Ave']), 'E': set(['Meridian Avenue E', '142nd Ave E']), 'East': set(['Meridian Avenue East', '75th Street East', '184th Avenue Court East', '142nd Avenue East', '204th Avenue East']), 'Meridian': set(['North Meridian', 'South Meridian']), 'South': set(['65th Avenue South', '49th Avenue South', '68th Avenue South', '63rd Avenue South', 'Airport Way South', '57th Avenue South', 'Crestwood Drive South', 'Woodley Avenue South', '1st Avenue South', 'Mill Avenue South', 'Martin Luther King Junior Way South', '70th Place South', 'Pacific Highway South', 'Luther Avenue South', '46th Avenue South', '50th Avenue South', 'Waters Avenue South', '42nd Avenue South', '62nd Avenue South', 'Lindsay Place South', 'Beacon Avenue South', '60th Avenue South', '56th Place South', 'Renton Avenue South', 'Williams Avenue South', '71st Place South', '41st Avenue South', 'Arrowsmith Avenue South', '58th Avenue South', '64th Avenue South', '66th Avenue South', 'Smithers Avenue South', '53rd Avenue South', '56th Avenue South', '74th Avenue South', 'Rainier Avenue South', '59th Avenue South', 'Holyoke Way South', '55th Avenue South', 'Wells Avenue South', '84th Avenue South', 'Morris Avenue South', 'Main Avenue South', 'Washington Avenue South', '61st Avenue South', '67th Avenue South', '54th Avenue South', 'Cornell Avenue South', 'Lakeridge Drive South', '40th Avenue South', '51st Avenue South', '69th Place South']), 'Southwest': set(['Monster Road Southwest', '7th Street Southwest'])})\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    st_types = audit(SAMPLE_FILE)\n",
    "    pprint.pprint(len(st_types)) \n",
    "    pprint.pprint(st_types)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Postal Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_postal_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def audit_postal_code(filename):\n",
    "    osmfile = open(filename)\n",
    "    \n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postal_code(tag):\n",
    "                    if len(tag.attrib['v']) > 5:\n",
    "                        print(tag.attrib['v'])\n",
    "    osmfile.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98057-4040\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    audit_postal_code(SAMPLE_FILE)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n"
     ]
    }
   ],
   "source": [
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "#import schemaf\n",
    "import schema\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "print(type(SCHEMA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \n",
    "    \n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        \n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            \n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    #print(schema)\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "   \n",
    "\n",
    "    def writerow(self, row):\n",
    "        #print(row)\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "            \n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'codecs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-285-78bc34424368>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# sample of the map when validating.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprocess_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSAMPLE_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Sravanthi\\data.py\u001b[0m in \u001b[0;36mprocess_map\u001b[1;34m(file_in, validate)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNODES_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnodes_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNODE_TAGS_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnodes_tags_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWAYS_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mways_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'codecs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    import codecs\n",
    "    \n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    \n",
    "    process_map(SAMPLE_FILE, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\"C:\\sqlite-windows\\sqlite_windows\\seattle.db\")\n",
    "c = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"select * from nodes where user = 'Skybunny'\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems in the map data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postal codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION ALL \\\n",
    "         SELECT * FROM ways_tags) tags \\\n",
    "         WHERE tags.key='postcode'\\\n",
    "         GROUP BY tags.value\\\n",
    "         ORDER BY count DESC;\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'98178', 249), (u'98118', 114), (u'98057', 23), (u'98371', 19), (u'98092', 13), (u'98042', 11), (u'98032', 10), (u'98001', 4), (u'98030', 4), (u'98354', 4), (u'98010', 2), (u'98027', 2), (u'98038', 2), (u'98055', 2), (u'98058', 2), (u'98059', 2), (u'98372', 2), (u'98391', 2), (u'90092', 1), (u'98003', 1), (u'98032-1762', 1), (u'98057-4040', 1), (u'98104', 1), (u'98108', 1), (u'98168', 1), (u'98188', 1), (u'98198', 1), (u'98321', 1), (u'98373', 1), (u'98374', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Cities by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION  \\\n",
    "         SELECT * FROM ways_tags) tags\\\n",
    "         WHERE tags.key = 'city'\\\n",
    "         GROUP BY tags.value\\\n",
    "         ORDER BY count DESC;\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Seattle', 365), (u'Renton', 29), (u'Kent', 25), (u'Puyallup', 24), (u'Auburn', 17), (u'Milton', 4), (u'Bonney Lake', 3), (u'Maple Valley', 3), (u'Black Diamond', 2), (u'Covington', 2), (u'Edgewood', 2), (u'Sumner', 2), (u'Algona', 1), (u'Buckley', 1), (u'Des Moines', 1), (u'Pacific', 1), (u'SeaTac', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Seattlemap.osm ......... 129 MB\n",
    "sample.osm ............. 13 MB\n",
    "seattle.db ............. 7 MB\n",
    "nodes.csv .............. 4 MB\n",
    "nodes_tags.csv ......... 267 KB\n",
    "ways.csv ............... 437 KB\n",
    "ways_tags.csv .......... 974 KB\n",
    "ways_nodes.cv .......... 1.7 MB  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(56861,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"select count(*) from nodes\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7266,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"select count(*) from ways\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(436,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"select count(distinct(e.uid)) from(select uid from nodes UNION ALL select uid from ways) e\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Contributing Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Omnific', 19989), (u'Grauer Elefant', 4687), (u'Amoebabadass', 4468), (u'STBrenden', 3977), (u'Glassman', 3680), (u'csytsma', 2836), (u'woodpeck_fixbot', 2403), (u'Geodesy99', 2245), (u'Skybunny', 1766), (u'zephyr', 1414)]\n"
     ]
    }
   ],
   "source": [
    "query = \"select e.user,count(*) as num from(select user from nodes UNION ALL select user from ways) e \n",
    "        GROUP BY e.user\n",
    "        ORDER BY num DESC\n",
    "        LIMIT 10;\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Users Appearing only once(having 1 post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(107,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM (SELECT e.user, COUNT(*) as num\\\n",
    "        FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\\\n",
    "        GROUP BY e.user HAVING num=1)  u;\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Appearing Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'restaurant', 42), (u'bench', 38), (u'fast_food', 34), (u'waste_basket', 20), (u'cafe', 19), (u'bank', 15), (u'doctors', 15), (u'fuel', 13), (u'dentist', 12), (u'school', 12)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT value, COUNT(*) as num FROM nodes_tags\\\n",
    "        WHERE key='amenity'\\\n",
    "        GROUP BY value\\\n",
    "        ORDER BY num DESC\\\n",
    "        LIMIT 10;\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biggest Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'christian', 6)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT nodes_tags.value, COUNT(*) as num\\\n",
    "         FROM nodes_tags \\\n",
    "         JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='place_of_worship') i\\\n",
    "         ON nodes_tags.id=i.id \\\n",
    "         WHERE nodes_tags.key='religion' \\\n",
    "         GROUP BY nodes_tags.value \\\n",
    "         ORDER BY num DESC \\\n",
    "         LIMIT 1;\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Popular Cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'pizza', 7), (u'japanese', 4), (u'chinese', 3), (u'asian', 2), (u'burger', 2), (u'mexican', 2), (u'thai', 2), (u'american;savory_pancakes;pancake;breakfast', 1), (u'barbecue', 1), (u'burger;asian', 1), (u'indian', 1), (u'italian', 1), (u'pancake;breakfast', 1), (u'vietnamese', 1)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT nodes_tags.value, COUNT(*) as num \\\n",
    "        FROM nodes_tags \\\n",
    "        JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i \\\n",
    "        ON nodes_tags.id=i.id \\\n",
    "        WHERE nodes_tags.key='cuisine' \\\n",
    "        GROUP BY nodes_tags.value \\\n",
    "        ORDER BY num DESC;\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "print(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
